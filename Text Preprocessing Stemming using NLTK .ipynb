{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ecd3282f-8a80-49e2-bba9-0e8d2b6b2b3f",
   "metadata": {},
   "source": [
    "### Text Preprocessing Stemming using NLTK"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10679a5a-4db4-46a0-aee3-5ec7dbeaebfb",
   "metadata": {},
   "source": [
    "#### Stemming\n",
    "\n",
    "Stemming is the process of reducing a word to its word stem that affixes to suffixes and prefixes or to the roots of words known as lemma.\n",
    "Stemming is important in natural language understanding (NLU) and natuaral language processing (NLP)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1439fbe0-2c95-4554-857a-e2eb3201c27e",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_list = ['eating','eats','eaten','writing','written','fairly','programming','programs','history','finally','finalize','sitting','congrats','congratulation','congratulating','sports','sportingly']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d8b546a-601f-4961-b697-a6f3b9a32eed",
   "metadata": {},
   "source": [
    "#### PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8cd210e9-11d3-4855-a416-75e521bc7f87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eating------->eat\n",
      "eats------->eat\n",
      "eaten------->eaten\n",
      "writing------->write\n",
      "written------->written\n",
      "fairly------->fairli\n",
      "programming------->program\n",
      "programs------->program\n",
      "history------->histori\n",
      "finally------->final\n",
      "finalize------->final\n",
      "sitting------->sit\n",
      "congrats------->congrat\n",
      "congratulation------->congratul\n",
      "congratulating------->congratul\n",
      "sports------->sport\n",
      "sportingly------->sportingli\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "stemmer = PorterStemmer()\n",
    "for word in word_list:\n",
    "    print(word+\"------->\"+stemmer.stem(word))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c4a8e7c-7bd8-4f6b-b33a-7d1e469cf2e5",
   "metadata": {},
   "source": [
    "#### RegexpStemmer Class\n",
    "\n",
    "NLTK has RegexpStemmer class with the help of which we can easily implement Regular Expression Stemmer algorithm.\n",
    "It basically takes a single regular expression and removes any prefix or suffix that matches the expression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "22580907-10f3-4d9d-9b0b-bafdaf029f3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'eat'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem import RegexpStemmer\n",
    "reg_stemmer = RegexpStemmer('ing$|s$|e$|able$', min=4)\n",
    "reg_stemmer.stem('eating')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f2c372da-f06f-41a3-8825-819d8dd05732",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ingeat'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg_stemmer.stem('ingeating')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4ae59a1c-c0e4-45a7-b685-091d0ccc9da5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'eat'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg_stemmer = RegexpStemmer('ing|s$|e$|able$', min=4)\n",
    "reg_stemmer.stem('eating')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "058daf38-b69d-46a5-83c6-77f40e6f5672",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'eat'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg_stemmer = RegexpStemmer('ing|s$|e$|able$', min=4)\n",
    "reg_stemmer.stem('ingeating')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae5e1dbe-d390-4b0f-9143-efe4f2bb5111",
   "metadata": {},
   "source": [
    "#### SnowballStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ffb5df82-b6f3-4d23-9dd9-1b17bd3d3814",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import SnowballStemmer\n",
    "snowball_stemmer = SnowballStemmer('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8046c3bb-8237-4abb-add7-c791bf36b6e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eating---->eat\n",
      "eats---->eat\n",
      "eaten---->eaten\n",
      "writing---->write\n",
      "written---->written\n",
      "fairly---->fair\n",
      "programming---->program\n",
      "programs---->program\n",
      "history---->histori\n",
      "finally---->final\n",
      "finalize---->final\n",
      "sitting---->sit\n",
      "congrats---->congrat\n",
      "congratulation---->congratul\n",
      "congratulating---->congratul\n",
      "sports---->sport\n",
      "sportingly---->sport\n"
     ]
    }
   ],
   "source": [
    "for word in word_list:\n",
    "    print(word+\"---->\"+snowball_stemmer.stem(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "57fb558e-b58c-40ca-add6-96052c81e7df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eating ----> eat\n",
      "eats ----> eat\n",
      "eaten ----> eaten\n",
      "writing ----> write\n",
      "written ----> written\n",
      "fairly ----> fair\n",
      "programming ----> program\n",
      "programs ----> program\n",
      "history ----> histori\n",
      "finally ----> final\n",
      "finalize ----> final\n",
      "sitting ----> sit\n",
      "congrats ----> congrat\n",
      "congratulation ----> congratul\n",
      "congratulating ----> congratul\n",
      "sports ----> sport\n",
      "sportingly ----> sport\n",
      "Stemmed Words List: ['eat', 'eat', 'eaten', 'write', 'written', 'fair', 'program', 'program', 'histori', 'final', 'final', 'sit', 'congrat', 'congratul', 'congratul', 'sport', 'sport']\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import SnowballStemmer\n",
    "\n",
    "# Initialize the SnowballStemmer\n",
    "snowball_stemmer = SnowballStemmer('english')\n",
    "\n",
    "# Example word list\n",
    "word_list = ['eating','eats','eaten','writing','written','fairly','programming','programs','history','finally','finalize','sitting','congrats','congratulation','congratulating','sports','sportingly']\n",
    "\n",
    "# Create a new list to store the stemmed words\n",
    "stemmed_wordlist = []\n",
    "\n",
    "# Stem each word and add it to the new list\n",
    "for word in word_list:\n",
    "    stemmed_word = snowball_stemmer.stem(word)\n",
    "    stemmed_wordlist.append(stemmed_word)\n",
    "    print(word + \" ----> \" + stemmed_word)\n",
    "\n",
    "# Display the final list of stemmed words\n",
    "print(\"Stemmed Words List:\", stemmed_wordlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb6fa6b3-f26e-4832-8b36-77b325b3c7f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0391e40-b70c-4bb4-9d75-2eaba8b06a75",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b94b743-b7e8-4263-8018-e3732f44f34d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2191b721-785f-4979-a1ad-bbcd15b0b866",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
